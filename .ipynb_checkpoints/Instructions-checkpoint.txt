Instructions and Workflow of a project

Part I:
1. Create a video with annotations of the classes you want to train later on (Not yet: Do that for multiple videos)
2. Extract the videos corresponding to the annotations using the function of the library. Save them in Data/Gloss1 .. Data/Gloss2 ..
3. Extract the frames for each video and save them in folder Data/Gloss1/0001 Data/Gloss2/0002 ..

Part II:
4. Run Openpose on each frame for each gloss and save the json file next to the original image. Now you should have in each folder the original frame, rendered frame and the json file

Part III:
5. Create h5 dataset file. The format should be ["Class for classification"]["Number of video"]["Coordinates of each frame"].
ex. ["1H"]["00007"]["098,0,23,..."]. Based on the Data folder now the dimensions should be 3 x 12 x total_no_frames
6. Reshape the dataset based on Input_shape of LSTM. (Samples, Time_steps, Features)